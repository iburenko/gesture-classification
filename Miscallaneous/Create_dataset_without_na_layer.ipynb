{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44617c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir as ls, path, makedirs\n",
    "import math\n",
    "import json\n",
    "import argparse\n",
    "from natsort import natsorted\n",
    "import cv2\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7632e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 29.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74e2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_home = r'/beegfs/.global0/ws/sapo684c-sac_space/split_test_trial.json'\n",
    "with open(split_home, 'r') as file:\n",
    "    split = json.load(file)\n",
    "train = split['train']\n",
    "val = split['val']\n",
    "test = split['test']\n",
    "csv_home=r'/projects/p_scads_bdai/ellen_show/labels/'\n",
    "na_layer = r'/projects/p072/p_scads_bdai/ellen_show/NA-layer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c4a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csvs = natsorted([elem for elem in ls(csv_home) if elem.endswith('csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd093dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_path = r'/beegfs/.global0/ws/sapo684c-sac_space/NA_layer/Ellen_dataset_trial/'\n",
    "base_path = r'/projects/p_scads_bdai/ellen_show/'\n",
    "OF_path = r'/projects/p072/p_scads_bdai/ellen_show/publish/'\n",
    "videos_home= r'/projects/p_scads_bdai/ellen_show/full_dataset_30_videos_yao_and_suwei/30_videos/'\n",
    "keypoints_home = path.join(base_path, 'publish')\n",
    "length_msec = 1300\n",
    "thr = 0.55\n",
    "user_input='yes'\n",
    "user_input =user_input.lower()\n",
    "pos_keywords= ['yes','true']\n",
    "OF_option_enabled= any(keyword in user_input for keyword in pos_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac2ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = node_path + \"/\" + \\\n",
    "            \"ellen_show_length_\" + str(length_msec) + \\\n",
    "            \"_iou_thr_\" + str(thr) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73908436",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in product([home_path], ['train', 'val', 'test'], ['gesture', 'nongesture']):\n",
    "    makedirs(path.join(*elem), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436746a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec2frame(sec):\n",
    "    return math.ceil(sec * FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b4d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def framelist2tensor(frame_list, video_shape, output_shape):\n",
    "    tensor = np.zeros((len(frame_list), *output_shape[::-1]))\n",
    "    rescale_x = output_shape[1]/video_shape[1]\n",
    "    rescale_y = output_shape[0]/video_shape[0]\n",
    "    limit_x = output_shape[1]\n",
    "    limit_y = output_shape[0]\n",
    "    for i, elem in enumerate(frame_list):\n",
    "        data = json.load(open(elem))\n",
    "        people = data['people']\n",
    "        for person in people:\n",
    "            keypoints = person['pose_keypoints_2d']\n",
    "            y = np.array(keypoints[::3]) * rescale_y\n",
    "            x = np.array(keypoints[1::3]) * rescale_x\n",
    "            y = np.clip(y, 0, limit_y - 1)\n",
    "            x = np.clip(x, 0, limit_x - 1)\n",
    "            for x_coord, y_coord in zip(x,y):\n",
    "                if x_coord == 0 and y_coord == 0:\n",
    "                    continue\n",
    "                tensor[i, round(x_coord), round(y_coord)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14b61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(csv_data, start_interval, end_interval, thr):\n",
    "    length = 0\n",
    "    for i in range(len(csv_data)):\n",
    "        start_time = csv_data['Begin Time - msec'].iloc[i]\n",
    "        end_time = csv_data['End Time - msec'].iloc[i]\n",
    "        if start_interval <= start_time < end_interval <= end_time:\n",
    "            length += (end_interval - start_time)\n",
    "        if start_interval <= start_time < end_time <= end_interval:\n",
    "            length += (end_time - start_time)\n",
    "        if start_time <= start_interval <= end_time:\n",
    "            length += (min(end_interval, end_time) - start_interval)\n",
    "        if start_time > end_interval:\n",
    "            break\n",
    "    iou = length/(end_interval - start_interval)\n",
    "    if iou > thr:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56223a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subclip2tensor(subclip,OF_frame_list,start_frame,end_frame,num_frames):\n",
    "    frame_tensor = np.zeros((num_frames, 320, 320, 3))\n",
    "    OF_frames = np.zeros((num_frames, 320, 320, 3))\n",
    "    OF_frame_tensor = np.zeros((num_frames, 320, 320, 6))\n",
    "    curr_frame = start_frame\n",
    "    #print(\"start and end\",start_frame,end_frame)\n",
    "    \n",
    "    #print(OF_frame_list)\n",
    "    frame_iterator = subclip.iter_frames()\n",
    "    for i, frame in enumerate(frame_iterator):\n",
    "        frame_tensor[i] = cv2.resize(frame, (320, 320))\n",
    "        #print('frame_tensor',i)\n",
    "        pattern =r'(\\d+)\\.png'\n",
    "        #print(pattern)\n",
    "        if re.search(pattern, OF_frame_list[i]):\n",
    "            #print(OF_frame_list[i])\n",
    "            extracted_number = re.findall(pattern, OF_frame_list[i])[0]\n",
    "            #print(extracted_number)\n",
    "            if curr_frame == int(extracted_number) -1:\n",
    "                #print(\"current_frame\",curr_frame)\n",
    "                OF_frame = cv2.imread(OF_frame_list[i])\n",
    "                OF_frames[i] = cv2.resize(OF_frame, (320,320))\n",
    "                OF_frame_tensor[i] = np.concatenate ((frame_tensor[i], OF_frames[i]), axis=2)\n",
    "        if curr_frame!=end_frame:\n",
    "            curr_frame +=1\n",
    "            #print('curr_frame',curr_frame)\n",
    "\n",
    "    #print(OF_frame_tensor[0])\n",
    "    return frame_tensor,OF_frame_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0435e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_list(frame_list, start_frame, end_frame, num_frames):\n",
    "    overhead = 0\n",
    "    if math.ceil(end_frame - start_frame) != num_frames:\n",
    "        overhead = (start_frame + num_frames - end_frame)\n",
    "        end_frame += overhead\n",
    "    return frame_list[start_frame:end_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f275150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(split, regime):\n",
    "    dataset_ind = 0\n",
    "    clip_length = length_msec/1000\n",
    "    num_frames = int(math.ceil(clip_length*29.97))\n",
    "    for elem in split:\n",
    "        case_name = elem.split('.')[0]\n",
    "        csv_file = [elem for elem in all_csvs if elem.startswith(case_name)][0]\n",
    "        csv_data = pd.read_csv(path.join(csv_home,csv_file))\n",
    "        csv_na = path.join(na_layer,csv_file)\n",
    "        with open(csv_na, mode='r') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            next(csv_reader)\n",
    "            first_row = next(csv_reader, None)\n",
    "            if first_row is None:\n",
    "                print(f\"CSV file {csv_na} is empty no data rows)\")\n",
    "                continue\n",
    "        \n",
    "        csv_data = csv_data[csv_data['Duration - msec']>=150]\n",
    "        csv_data = csv_data.reset_index()\n",
    "        video_path = path.join(videos_home, elem)\n",
    "        video_obj = VideoFileClip(video_path)\n",
    "        video_duration = np.floor(video_obj.duration).astype('int')\n",
    "        #print(video_duration)\n",
    "        i = 0\n",
    "        start_msec = 0\n",
    "        all_files_home = path.join(keypoints_home, case_name, case_name+'_json')\n",
    "        all_files = natsorted(ls(all_files_home))\n",
    "        OF_file = path.join(OF_path,case_name, case_name+ '_OF',case_name+'_OF_SSR_1')\n",
    "        OF_file_all =natsorted(ls(OF_file))\n",
    "        while start_msec/1000 + 2*clip_length < video_duration:\n",
    "            start_sec, end_sec = i * clip_length, (i + 1) * clip_length\n",
    "            start_msec = start_sec * 1000\n",
    "            end_msec = end_sec * 1000\n",
    "            print(start_msec,end_msec)\n",
    "            \n",
    "            \n",
    "            with open(csv_na, mode='r') as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                next(csv_reader)\n",
    "                print('yes')\n",
    "                print(csv_reader)\n",
    "                process_flag = True\n",
    "                for row in csv_reader:\n",
    "                    print('row',row)\n",
    "                    start_time = int(row[1])\n",
    "                    end_time = int(row[2])\n",
    "                    print('STart and end time',start_time, end_time)\n",
    "                    if not (start_msec < start_time and end_msec < start_time) and not (start_msec > end_time and end_msec > end_time):\n",
    "                        process_flag = False\n",
    "                        print(f\"This belongs to the na layer ({start_time}, {end_time}\")\n",
    "                        break\n",
    "                if process_flag:\n",
    "                    start_frame = sec2frame(i*clip_length)\n",
    "                    end_frame = sec2frame((i+1)*clip_length)\n",
    "                    #print(start_frame,end_frame)\n",
    "                    frame_list = get_frame_list(all_files, start_frame, end_frame, num_frames)\n",
    "                    frame_list = [path.join(all_files_home, elem) for elem in frame_list]\n",
    "                    OF_frame_list = get_frame_list(OF_file_all, start_frame, end_frame, num_frames)\n",
    "                    OF_frame_list = [path.join(OF_file, elem)for elem in OF_frame_list]\n",
    "                    keypoints_tensor = framelist2tensor(frame_list, video_obj.size, (320,320))\n",
    "                    label = get_label(csv_data, start_msec, end_msec, thr)   \n",
    "                    subclip = video_obj.subclip(i*clip_length, (i+1)*clip_length)\n",
    "                    clip_tensor, OF_clip_tensor = subclip2tensor(subclip,OF_frame_list,start_frame,end_frame, num_frames)\n",
    "\n",
    "                    if OF_option_enabled:\n",
    "                        input_item = {\n",
    "                            'video': clip_tensor.astype('uint8'),\n",
    "                            'keypoints': keypoints_tensor.astype('uint8'),\n",
    "                            'video_OF':OF_clip_tensor.astype('uint8'),\n",
    "                        }\n",
    "                    else:\n",
    "                        input_item = {\n",
    "                            'video': clip_tensor.astype('uint8'),\n",
    "                            'keypoints': keypoints_tensor.astype('uint8'),\n",
    "                        }\n",
    "                    elem_splitted = elem.split('_')\n",
    "                    suffix = elem_splitted[0] + '_' + elem_splitted[-1].split('.')[0]\n",
    "                    suffix1 =suffix + f'_{int(start_msec)}_{int(end_msec)}'\n",
    "                    filename = '0'*(9 - len(str(dataset_ind))) + str(dataset_ind) + '_' + suffix1\n",
    "                    if label:\n",
    "                        filename = home_path + regime + '/gesture/' + filename\n",
    "                    else:\n",
    "                        filename = home_path + regime + '/nongesture/' + filename\n",
    "                    np.savez_compressed(filename, **input_item)\n",
    "                    dataset_ind += 1\n",
    "                    i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "                    continue\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "830f64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(split, regime):\n",
    "    dataset_ind = 0\n",
    "    clip_length = length_msec/1000\n",
    "    num_frames = int(math.ceil(clip_length*29.97))\n",
    "    for elem in split:\n",
    "        case_name = elem.split('.')[0]\n",
    "        csv_file = [elem for elem in all_csvs if elem.startswith(case_name)][0]\n",
    "        csv_data = pd.read_csv(path.join(csv_home,csv_file))\n",
    "        csv_na = path.join(na_layer,csv_file)\n",
    "        \n",
    "        csv_data = csv_data[csv_data['Duration - msec']>=150]\n",
    "        csv_data = csv_data.reset_index()\n",
    "        video_path = path.join(videos_home, elem)\n",
    "        video_obj = VideoFileClip(video_path)\n",
    "        video_duration = np.floor(video_obj.duration).astype('int')\n",
    "        #print(video_duration)\n",
    "        i = 0\n",
    "        start_msec = 0\n",
    "        all_files_home = path.join(keypoints_home, case_name, case_name+'_json')\n",
    "        all_files = natsorted(ls(all_files_home))\n",
    "        OF_file = path.join(OF_path,case_name, case_name+ '_OF',case_name+'_OF_SSR_1')\n",
    "        OF_file_all =natsorted(ls(OF_file))\n",
    "        while start_msec/1000 + 2*clip_length < video_duration:\n",
    "            start_sec, end_sec = i * clip_length, (i + 1) * clip_length\n",
    "            start_msec = start_sec * 1000\n",
    "            end_msec = end_sec * 1000\n",
    "            print(start_msec,end_msec) \n",
    "            with open(csv_na, mode='r') as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                next(csv_reader)\n",
    "                first_row = next(csv_reader, None)\n",
    "                if first_row is None:\n",
    "                    print(f\"CSV file {csv_na} is empty no data rows)\")\n",
    "                    \n",
    "                    \n",
    "                    start_frame = sec2frame(i*clip_length)\n",
    "                    end_frame = sec2frame((i+1)*clip_length)\n",
    "                    #print(start_frame,end_frame)\n",
    "                    frame_list = get_frame_list(all_files, start_frame, end_frame, num_frames)\n",
    "                    frame_list = [path.join(all_files_home, elem) for elem in frame_list]\n",
    "                    OF_frame_list = get_frame_list(OF_file_all, start_frame, end_frame, num_frames)\n",
    "                    OF_frame_list = [path.join(OF_file, elem)for elem in OF_frame_list]\n",
    "                    keypoints_tensor = framelist2tensor(frame_list, video_obj.size, (320,320))\n",
    "                    label = get_label(csv_data, start_msec, end_msec, thr)   \n",
    "                    subclip = video_obj.subclip(i*clip_length, (i+1)*clip_length)\n",
    "                    clip_tensor, OF_clip_tensor = subclip2tensor(subclip,OF_frame_list,start_frame,end_frame, num_frames)\n",
    "\n",
    "                    if OF_option_enabled:\n",
    "                        input_item = {\n",
    "                            'video': clip_tensor.astype('uint8'),\n",
    "                            'keypoints': keypoints_tensor.astype('uint8'),\n",
    "                            'video_OF':OF_clip_tensor.astype('uint8'),\n",
    "                        }\n",
    "                    else:\n",
    "                        input_item = {\n",
    "                            'video': clip_tensor.astype('uint8'),\n",
    "                            'keypoints': keypoints_tensor.astype('uint8'),\n",
    "                        }\n",
    "                    elem_splitted = elem.split('_')\n",
    "                    suffix = elem_splitted[0] + '_' + elem_splitted[-1].split('.')[0]\n",
    "                    suffix1 =suffix + f'_{int(start_msec)}_{int(end_msec)}'\n",
    "                    filename = '0'*(9 - len(str(dataset_ind))) + str(dataset_ind) + '_' + suffix1\n",
    "                    if label:\n",
    "                        filename = home_path + regime + '/gesture/' + filename\n",
    "                    else:\n",
    "                        filename = home_path + regime + '/nongesture/' + filename\n",
    "                    np.savez_compressed(filename, **input_item)\n",
    "                    dataset_ind += 1\n",
    "                    i += 1\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    \n",
    "                    print('yes')\n",
    "                    csv_file.seek(0)\n",
    "                    csv_reader1 = csv.reader(csv_file)\n",
    "                    next(csv_reader1)\n",
    "                    process_flag = True\n",
    "                    for row in csv_reader1:\n",
    "                        print('row',row)\n",
    "                        start_time = int(row[1])\n",
    "                        end_time = int(row[2])\n",
    "                        print('STart and end time',start_time, end_time)\n",
    "                        if not (start_msec < start_time and end_msec < start_time) and not (start_msec > end_time and end_msec > end_time):\n",
    "                            process_flag = False\n",
    "                            print(f\"This belongs to the na layer ({start_time}, {end_time}\")\n",
    "                            break\n",
    "                    if process_flag:\n",
    "                        start_frame = sec2frame(i*clip_length)\n",
    "                        end_frame = sec2frame((i+1)*clip_length)\n",
    "                        #print(start_frame,end_frame)\n",
    "                        frame_list = get_frame_list(all_files, start_frame, end_frame, num_frames)\n",
    "                        frame_list = [path.join(all_files_home, elem) for elem in frame_list]\n",
    "                        OF_frame_list = get_frame_list(OF_file_all, start_frame, end_frame, num_frames)\n",
    "                        OF_frame_list = [path.join(OF_file, elem)for elem in OF_frame_list]\n",
    "                        keypoints_tensor = framelist2tensor(frame_list, video_obj.size, (320,320))\n",
    "                        label = get_label(csv_data, start_msec, end_msec, thr)   \n",
    "                        subclip = video_obj.subclip(i*clip_length, (i+1)*clip_length)\n",
    "                        clip_tensor, OF_clip_tensor = subclip2tensor(subclip,OF_frame_list,start_frame,end_frame, num_frames)\n",
    "\n",
    "                        if OF_option_enabled:\n",
    "                            input_item = {\n",
    "                                'video': clip_tensor.astype('uint8'),\n",
    "                                'keypoints': keypoints_tensor.astype('uint8'),\n",
    "                                'video_OF':OF_clip_tensor.astype('uint8'),\n",
    "                            }\n",
    "                        else:\n",
    "                            input_item = {\n",
    "                                'video': clip_tensor.astype('uint8'),\n",
    "                                'keypoints': keypoints_tensor.astype('uint8'),\n",
    "                            }\n",
    "                        elem_splitted = elem.split('_')\n",
    "                        suffix = elem_splitted[0] + '_' + elem_splitted[-1].split('.')[0]\n",
    "                        suffix1 =suffix + f'_{int(start_msec)}_{int(end_msec)}'\n",
    "                        filename = '0'*(9 - len(str(dataset_ind))) + str(dataset_ind) + '_' + suffix1\n",
    "                        if label:\n",
    "                            filename = home_path + regime + '/gesture/' + filename\n",
    "                        else:\n",
    "                            filename = home_path + regime + '/nongesture/' + filename\n",
    "                        np.savez_compressed(filename, **input_item)\n",
    "                        dataset_ind += 1\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32af11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Start creating train dataset!\")\n",
    "    create_dataset(split[\"train\"], \"train\")\n",
    "    print(\"Start creating val dataset!\")\n",
    "    create_dataset(split[\"val\"], \"val\")\n",
    "    print(\"Start creating test dataset!\")\n",
    "    create_dataset(split[\"test\"], \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cretdst_alp",
   "language": "python",
   "name": "cretdst_alp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
