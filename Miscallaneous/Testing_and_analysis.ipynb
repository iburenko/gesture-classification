{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c96598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load C:\\Users\\sachu\\Desktop\\My_Documents\\Thesis\\Base_model\\Existing_model\\gesture_classification\\run_classification.py\n",
    "from argparse import ArgumentParser\n",
    "import logging\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from gesture_classification.datasets import SnippetClassificationLightningDataset\n",
    "from gesture_classification.model import LitModel\n",
    "from gesture_classification.helpers import (\n",
    "    get_num_frames, get_subsample_rate,\n",
    "    get_accelerator, parse_use_keypoints\n",
    ")\n",
    "from gesture_classification.constants import SEED\n",
    "\n",
    "logging.getLogger(\"lightning\").setLevel(logging.WARNING)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267bc47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "dataset_home = r'/beegfs/.global0/ws/sapo684c-sac_space/Ellen_Dataset_with_Optical_Flow_Masking_Final/ellen_show_length_1300_sample_rate_1_iou_0.55'\n",
    "logger_name = \"gesture_classification\"\n",
    "logger_folder = r'/beegfs/ws/0/sapo684c-sac_space/Gesture_Classification/Logger_File'\n",
    "batch_size = 1\n",
    "model_name = \"videomae\"\n",
    "pretrained_model = \"MCG-NJU/videomae-base-finetuned-ssv2\"\n",
    "#zero_normalisation=True\n",
    "nodes = 1\n",
    "gpus = 1\n",
    "epochs = 2\n",
    "num_workers = 16 * gpus\n",
    "accumulate_batches = 8\n",
    "learning_rate = 1e-5\n",
    "save_top_k = 1\n",
    "precision = 16\n",
    "use_keypoints = 0\n",
    "seed_everything(SEED, workers=True)\n",
    "subsample_rate = get_subsample_rate(dataset_home)\n",
    "num_frames = get_num_frames(dataset_home, subsample_rate)\n",
    "accelerator = get_accelerator()\n",
    "dm = SnippetClassificationLightningDataset(\n",
    "    dataset_home, \n",
    "    batch_size, \n",
    "    num_workers, \n",
    "    subsample_rate, \n",
    "    num_frames,\n",
    "    #zero_normalisation,\n",
    "    use_keypoints, \n",
    "    )\n",
    "model = LitModel(\n",
    "    model_name, pretrained_model, num_frames, learning_rate, use_keypoints\n",
    "    )\n",
    "model.save_hyperparameters()\n",
    "checkpoint_f1 = ModelCheckpoint(\n",
    "    save_top_k=save_top_k, mode=\"max\", monitor=\"val_f1\",\n",
    "    filename=\"checkpoint-{epoch:02d}-{val_f1:.2f}\"\n",
    "    )\n",
    "checkpoint_acc = ModelCheckpoint(\n",
    "    save_top_k=save_top_k, mode=\"max\", monitor=\"val_acc\",\n",
    "    filename=\"checkpoint-{epoch:02d}-{val_acc:.2f}\"\n",
    "    )\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "checkpoint_path = r'/beegfs/ws/0/sapo684c-sac_space/Gesture_Classification/Logger_File/gesture_classification/version_162/checkpoints/checkpoint-epoch=135-val_acc=0.79.ckpt'\n",
    "loaded_model = model.load_from_checkpoint(checkpoint_path,num_frames =num_frames)\n",
    "match = re.search(r'version_(\\d+)', checkpoint_path)\n",
    "version_string=match.group(0)\n",
    "\n",
    "#logger = TensorBoardLogger(\n",
    " #   name=logger_name,\n",
    "  #  save_dir=logger_folder)\n",
    "trainer = Trainer(\n",
    "    accelerator=accelerator,\n",
    "    devices=gpus,\n",
    "    num_nodes=nodes,\n",
    "    max_epochs=epochs,\n",
    "    strategy='dp',\n",
    "    precision=precision,\n",
    "    enable_progress_bar=False,\n",
    "    callbacks=[checkpoint_f1, checkpoint_acc, lr_monitor],\n",
    "    #logger=logger,\n",
    "    accumulate_grad_batches=accumulate_batches,\n",
    "    )\n",
    "#test_results = trainer.test(loaded_model, dm)\n",
    "start_time= time.time()\n",
    "test_results = trainer.test(loaded_model, dm.train_dataloader())\n",
    "end_time = time.time()\n",
    "total_time =end_time-start_time\n",
    "print(f\"Total Time: {total_time:.2f} seconds\")\n",
    "\"\"\"\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--dataset-home\", type=str, default =r'/beegfs/ws/0/sapo684c-sac_space/ellen_show_dataset_trial_OF/ellen_show_length_1300_sample_rate_8_iou_0.55')\n",
    "parser.add_argument(\"--logger-name\", type=str, default=\"gesture_classification\")\n",
    "parser.add_argument(\"--logger-folder\", type=str, default=r'/beegfs/ws/0/sapo684c-sac_space/Gesture_Classification/Logger_File')\n",
    "parser.add_argument(\"--pretrained-model\", type=str, default=\"\")\n",
    "parser.add_argument(\"--pretrained-dataset\", type=str, default=\"ssv2\")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=2)\n",
    "parser.add_argument(\"--precision\", type=int, default=16)\n",
    "parser.add_argument(\"--save-top-k\", type=int, default=1)\n",
    "parser.add_argument(\"--learning-rate\", type=float, default=1e-4)\n",
    "parser.add_argument(\"--nodes\", type=int, default=1)\n",
    "parser.add_argument(\"--gpus\", type=int, default=1)\n",
    "parser.add_argument(\"--workers-per-gpu\", type=int, default=16)\n",
    "parser.add_argument(\"--accumulate-batches\", type=int, default=8)\n",
    "parser.add_argument(\"--epochs\", type=int,default=2)\n",
    "parser.add_argument(\"--use-keypoints\", default=0)\n",
    "parser.add_argument(\"--model-name\", type=str,default=\"videomae\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(args)\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4c2d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions =loaded_model.predictions_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5552a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =loaded_model.ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d1b87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=loaded_model.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dabafd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd9630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_list = [filename for sublist in filenames for filename in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f687a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_ground_list = [filename for sublist in ground_truth for filename in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbfaa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_ground_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd433b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_prediction_list = [filename for sublist in predictions for filename in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd4891",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0615a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flattened_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc2ec90",
   "metadata": {},
   "source": [
    "# Writing CSV for ELAN software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a50d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51fc636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "previous_file_group = None\n",
    "output=r'/beegfs/.global0/ws/sapo684c-sac_space/ELAN_Mapping_prediction/Train_dataset'\n",
    "output_dir= os.path.join(output,version_string)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for filename, ground, prediction in zip(flattened_list, flattened_ground_list, flattened_prediction_list):\n",
    "    file_group = filename.split('_')[1:]\n",
    "    file_group = '_'.join(file_group)\n",
    "    file_group = file_group.split('.')[0]\n",
    "    \n",
    "    if file_group != previous_file_group: \n",
    "        if previous_file_group is not None:\n",
    "           \n",
    "            output_filename = f'{previous_file_group}.csv'\n",
    "            df = pd.DataFrame(data, columns=['Filename', 'Ground Truth', 'Predictions', 'Start Time', 'End Time'])\n",
    "            out1=os.path.join(output_dir,output_filename)\n",
    "            df.to_csv(out1, index=False)\n",
    "            print(f\"CSV file '{output_filename}' generated successfully.\")\n",
    "        \n",
    "        data = []\n",
    "        start_time = 0\n",
    "        end_time = 1300\n",
    "        previous_file_group = file_group\n",
    "    \n",
    "    data.append([filename, ground, prediction, start_time, end_time])\n",
    "    start_time = end_time\n",
    "    end_time += 1300\n",
    "\n",
    "\n",
    "if previous_file_group is not None:\n",
    "    output_filename = f'{previous_file_group}.csv'\n",
    "    df = pd.DataFrame(data, columns=['Filename', 'Ground Truth', 'Predictions', 'Start Time', 'End Time'])\n",
    "    out2=os.path.join(output_dir,output_filename)\n",
    "    df.to_csv(out2, index=False)\n",
    "    print(f\"CSV file '{output_filename}' generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879232b3",
   "metadata": {},
   "source": [
    "# Writing CSV for ELAN software with taking time from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "836514f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8891eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "previous_file_group = None\n",
    "output=r'/beegfs/.global0/ws/sapo684c-sac_space/ELAN_Mapping_prediction'\n",
    "output_dir= os.path.join(output,version_string)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for filename, ground, prediction in zip(flattened_list, flattened_ground_list, flattened_prediction_list):\n",
    "    file_group = filename.split('_')[1:3]\n",
    "    file_group = '_'.join(file_group)\n",
    "    file_group = file_group.split('.')[0]\n",
    "    start_time = filename.split('_')[3]\n",
    "    end_time = filename.split('_')[4].split('.')[0]\n",
    "    #print(file_group)\n",
    "    \n",
    "    if file_group != previous_file_group: \n",
    "        if previous_file_group is not None:\n",
    "            #print('PREvious_File_group',previous_file_group)\n",
    "           \n",
    "            output_filename = f'{previous_file_group}.csv'\n",
    "            df = pd.DataFrame(data, columns=['Filename', 'Ground Truth', 'Predictions', 'Start Time', 'End Time'])\n",
    "            out1=os.path.join(output_dir,output_filename)\n",
    "            df.to_csv(out1, index=False)\n",
    "            print(f\"CSV file '{output_filename}' generated successfully.\")\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        previous_file_group = file_group\n",
    "        #print(start_time,end_time)\n",
    "    \n",
    "    data.append([filename, ground, prediction, start_time, end_time])\n",
    "    #start_time = end_time\n",
    "    #end_time += 1300\n",
    "\n",
    "\n",
    "if previous_file_group is not None:\n",
    "    output_filename = f'{previous_file_group}.csv'\n",
    "    df = pd.DataFrame(data, columns=['Filename', 'Ground Truth', 'Predictions', 'Start Time', 'End Time'])\n",
    "    out2=os.path.join(output_dir,output_filename)\n",
    "    df.to_csv(out2, index=False)\n",
    "    print(f\"CSV file '{output_filename}' generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ea119",
   "metadata": {},
   "source": [
    "# Precision_Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "057d7149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17789b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=flattened_ground_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d94281b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores=flattened_prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38529f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "area = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b36527",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC value: {area:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5de79b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f\"Masking:-(AUC = {area:.2f})\")\n",
    "#plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8eace",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1af56d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b828133",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143bc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9d5d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b86e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fp=\"/beegfs/.global0/ws/sapo684c-sac_space/ELAN_Mapping_prediction/prec_rec_v106_train.csv\"\n",
    "data = list(zip(y_true,y_scores))\n",
    "with open(fp,mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['GT-106','PT-106'])\n",
    "    writer.writerows(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18821cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename=r\"/beegfs/.global0/ws/sapo684c-sac_space/ELAN_Mapping_prediction/prec_rec_1300_train_msec.csv\"\n",
    "data=[]\n",
    "with open(csv_filename, 'r') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    header = next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "print(data)\n",
    "new_header = header + [\"GT-v106\", \"PT-v106\"]\n",
    "combined_data = []\n",
    "for existing_row, val1, val2 in zip(data, y_true, y_scores):\n",
    "    combined_data.append(existing_row + [val1, val2])\n",
    "\n",
    "\n",
    "\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(new_header)\n",
    "    csv_writer.writerows(combined_data)\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' updated successfully.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e850da",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace with your actual y_scores data\n",
    "\n",
    "csv_filename=r\"/beegfs/.global0/ws/sapo684c-sac_space/ELAN_Mapping_prediction/prec_rec_250_without_NA_layer_msec.csv\"\n",
    "\n",
    "# Create a list of lists with custom headers\n",
    "new_data = [[\"GT-v230\", \"PT-v230\"]]  # Headers for y_true and y_scores\n",
    "new_data += [[yt, ys] for yt, ys in zip(y_true, y_scores)]\n",
    "\n",
    "# Write data with custom headers to a new CSV file\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerows(new_data)\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785dcef6",
   "metadata": {},
   "source": [
    "# Precision-Recall curve All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5714e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1656"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfdb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Load the CSV file using pandas\n",
    "csv_filename = \"/beegfs/.global0/ws/sapo684c-sac_space/ELAN_Mapping_prediction/prec_rec_250_msec.csv\"  # Update with your file name\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# List of versions\n",
    "version_labels = {'v228': '3-OF', 'v225': '3-VC', 'v237': '6-channel'}\n",
    "#version_labels = {'v104': '3-OF', 'v98': '3-VC', 'v106': '6-channel'}\n",
    "versions= [106,104,98]\n",
    "\n",
    "# Iterate through each version\n",
    "for version in version_labels.keys():\n",
    "    gt_column = f\"GT-{version}\"\n",
    "    pt_column = f\"PT-{version}\"\n",
    "\n",
    "    gt_values = df[gt_column]\n",
    "    pt_values = df[pt_column]\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(gt_values, pt_values)\n",
    "    area = auc(recall, precision)\n",
    "\n",
    "    plt.plot(recall, precision, label=f\"{version_labels[version]} (AUC = {area:.2f})\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curves for Different Versions\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(0, 1.02)  # Set x-axis limits\n",
    "plt.ylim(0.3, 1.02)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35038616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Load the CSV file using pandas\n",
    "csv_filename = \"/beegfs/.global0/ws/sapo684c-sac_space/ELAN_Mapping_prediction/prec_rec_250_msec.csv\"  # Update with your file name\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Define version-label mappings\n",
    "version_labels = {'v228': '3-OF', 'v225': '3-VC', 'v237': '6-channel'}\n",
    "\n",
    "# Iterate through each version\n",
    "for version in version_labels.keys():\n",
    "    gt_column = f\"GT-{version}\"\n",
    "    pt_column = f\"PT-{version}\"\n",
    "\n",
    "    gt_values = df[gt_column]\n",
    "    pt_values = df[pt_column]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(gt_values, pt_values)\n",
    "    area = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f\"{version_labels[version]} (AUC = {area:.2f})\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves for Different Versions\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff546cb5",
   "metadata": {},
   "source": [
    "# Correct Prob Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfbce842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93097641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val1, val2,val3 in zip(flattened_ground_list,flattened_prediction_list,flattened_list):\n",
    "    print(val1,val2,val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1d3236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg=[]\n",
    "pos=[]\n",
    "for elem1, elem2 in zip(flattened_ground_list,flattened_prediction_list):\n",
    "    if elem1==0.0:\n",
    "        neg.append(elem2)\n",
    "    else:\n",
    "        pos.append(elem2)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(neg, bins=40, histtype= 'bar', alpha =0.5, label='non-gesture')\n",
    "plt.hist(pos, bins=40, histtype= 'bar',alpha =0.5,label='gesture')\n",
    "plt.xlabel(\"predictions\")\n",
    "plt.title('Distribution of predictions')\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a50bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a2c5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ba993",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=neg\n",
    "data2=pos\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.kdeplot(data1, shade=True, label=\"Non gesture\",bw_adjust=0.4)\n",
    "sns.kdeplot(data2, shade=True, label=\"gesture\",bw_adjust=0.4)\n",
    "plt.xlabel(\"predictions\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"Prediction analysis\")\n",
    "plt.legend(loc='upper center')\n",
    "plt.ylim(0,10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f33a4",
   "metadata": {},
   "source": [
    "# Analysis of FN, FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d5c37",
   "metadata": {},
   "source": [
    "Writing all prediction for all snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0190d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full=[]\n",
    "for val1, val2,val3 in zip(flattened_ground_list,flattened_prediction_list,flattened_list):\n",
    "    dist={'GT':np.float(val1),'PT':np.float(val2),'File':val3}\n",
    "    full.append(dist)     \n",
    "        \n",
    "newfp=r'/beegfs/.global0/ws/sapo684c-sac_space/Testing_from_models/False_positive_negative_analysis/version98.json'\n",
    "\n",
    "import json\n",
    "with open(newfp,'w') as file:\n",
    "    json.dump(full,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c0aef",
   "metadata": {},
   "source": [
    "Writing prediction for FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FN=[]\n",
    "FP=[]\n",
    "for val1, val2,val3 in zip(flattened_ground_list,flattened_prediction_list,flattened_list):\n",
    "    if val1==0 and val2>=0.5:\n",
    "        dist={'GT':np.float(val1),'PT':np.float(val2),'File':val3}\n",
    "        FP.append(dist)\n",
    "    if val1==1 and val2<0.5:\n",
    "        dist={'GT':np.float(val1),'PT':np.float(val2),'File':val3}\n",
    "        FN.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0849a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong=FP+FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newfp=r'/beegfs/.global0/ws/sapo684c-sac_space/Testing_from_models/False_positive_negative_analysis/version98_FP_FN.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(newfp,'w') as file:\n",
    "    json.dump(wrong,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(newfp, 'r') as file:\n",
    "    loaded_data = json.load(file)\n",
    "\n",
    "print(loaded_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arupi_alp",
   "language": "python",
   "name": "arupi_alp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
